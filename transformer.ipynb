{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Transformer Formality Transfer Model\n",
    "\n",
    "References:\n",
    "- https://keras.io/examples/nlp/neural_machine_translation_with_transformer/\n",
    "- https://github.com/lukas/ml-class/blob/master/videos/cnn-text/imdb-embedding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Layer, MultiHeadAttention, Dense, LayerNormalization, Lambda, Dropout, Softmax, TextVectorization\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.models import Model, Sequential\n",
    "from keras import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = None\n",
    "vocab_size = 15000\n",
    "\n",
    "with open(\"labelled.txt\", \"r\") as l:\n",
    "    raw_data = l.read()\n",
    "lines = [x.strip() for x in raw_data.split(\"\\n\")]\n",
    "max_length = max(len(i) for i in lines)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(0, len(lines)-1 if num_samples is None else min(len(lines)-1,num_samples*2), 2):\n",
    "    X.append(lines[i])\n",
    "    Y.append(f\"[start] {lines[i+1]} [end]\")\n",
    "\n",
    "train_prop = 0.9\n",
    "train_num = int(train_prop * len(X))\n",
    "\n",
    "X_train, X_test = X[:train_num], X[train_num:]\n",
    "Y_train, Y_test = Y[:train_num], Y[train_num:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "\n",
    "X_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=max_length,\n",
    ")\n",
    "X_vectorization.adapt(X_train)\n",
    "\n",
    "Y_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "Y_vectorization.adapt(Y_train)\n",
    "\n",
    "def format_dataset(X, Y):\n",
    "    X = X_vectorization(X)\n",
    "    Y = Y_vectorization(Y)\n",
    "    return (\n",
    "        {\"encoder_inputs\": X, \"decoder_inputs\": Y[:, :-1]},\n",
    "        Y[:, 1:]\n",
    "    )\n",
    "\n",
    "def make_dataset(X, Y, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y)).batch(batch_size)\n",
    "    return dataset.map(format_dataset).shuffle(2048).prefetch(16).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = Sequential(\n",
    "            [Dense(dense_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = LayerNormalization()\n",
    "        self.layernorm_2 = LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        padding_mask = None\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = Sequential(\n",
    "            [Dense(latent_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = LayerNormalization()\n",
    "        self.layernorm_2 = LayerNormalization()\n",
    "        self.layernorm_3 = LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        padding_mask = None\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding (Position  (None, None, 256)   3993600     ['encoder_inputs[0][0]']         \n",
      " alEmbedding)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 15000)  13108120    ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,257,176\n",
      "Trainable params: 20,257,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "checkpoints_dir = os.path.abspath(\"transformer-checkpoints\")\n",
    "\n",
    "encoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(max_length, vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embedding_dim, latent_dim, num_heads)(x)\n",
    "encoder = Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = Input(shape=(None, embedding_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(max_length, vocab_size, embedding_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embedding_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = Dropout(0.5)(x)\n",
    "decoder_outputs = Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "model = Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    \"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter(Callback):\n",
    "    id_counter = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.id = f\"plot-{Plotter.id_counter}\"\n",
    "        Plotter.id_counter += 1\n",
    "        self.fig, self.ax = plt.subplots(figsize=(24, 6), dpi=80)\n",
    "        self.ax.set_xlabel(\"Epoch\")\n",
    "        self.ax.set_ylabel(\"Loss\")\n",
    "        self.ax.xaxis.set_major_locator(ticker.MultipleLocator(base=10.0))\n",
    "        self.ax.xaxis.set_minor_locator(ticker.MultipleLocator(base=1.0))\n",
    "        # self.ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.1))\n",
    "        # self.ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.02))\n",
    "        self.ax.grid(which=\"major\", color=\"#888888\")\n",
    "        self.ax.grid(which=\"minor\", color=\"#bbbbbb\")\n",
    "\n",
    "        self.fig.patch.set_facecolor(\"white\")\n",
    "        box = self.ax.get_position()\n",
    "        self.ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        display.display(self.fig, display_id=self.id)\n",
    "\n",
    "        self.max_loss = -1\n",
    "\n",
    "        self.epochs = []\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for l in self.ax.lines:\n",
    "            l.remove()\n",
    "        \n",
    "        self.epochs.append(epoch)\n",
    "        self.train_losses.append(t_loss:=logs[\"loss\"])\n",
    "        self.val_losses.append(v_loss:=logs[\"val_loss\"])\n",
    "\n",
    "        self.max_loss = max(self.max_loss, t_loss, v_loss)\n",
    "        \n",
    "        t_line, = self.ax.plot(self.epochs, self.train_losses, c=\"#55CDFC\")\n",
    "        v_line, = self.ax.plot(self.epochs, self.val_losses, c=\"#F7A8B8\")\n",
    "        self.ax.autoscale()\n",
    "        self.ax.set_ylim(0, self.max_loss * 1.1)\n",
    "        self.ax.legend([t_line, v_line], [\"Training\", \"Validation\"], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        display.update_display(self.fig, display_id=self.id)\n",
    "\n",
    "class PrintDemo(Callback):\n",
    "    def __init__(self, demo_str):\n",
    "        super().__init__()\n",
    "        self.start_time = time.time()\n",
    "        self.last_time = self.start_time\n",
    "        self.demo_str = demo_str\n",
    "    \n",
    "    def format_time(self, seconds):\n",
    "        if seconds < 60:\n",
    "            return f\"{seconds:.2f}s\"\n",
    "        elif seconds < 3600:\n",
    "            return f\"{(seconds/60):.2f}min\"\n",
    "        else:\n",
    "            return f\"{(seconds/3600):.2f}hr\"\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch == 0:\n",
    "            return\n",
    "        now = time.time()\n",
    "        elapsed = now-self.start_time\n",
    "        pred_str = decode_sequence(self.demo_str)\n",
    "        max_preview_length = 50\n",
    "        preview = (pred_str[:max_preview_length] + '...') if len(pred_str) > max_preview_length else pred_str\n",
    "\n",
    "        print(f\"Time for Epoch: {self.format_time(now-self.last_time)}, Total Elapsed: {self.format_time(elapsed)}, Total ETA: {self.format_time(elapsed/epoch * (epochs-epoch))}\")\n",
    "        print(f\"\\\"{demo_str}\\\" -> \\\"{preview}\\\"\\n\")\n",
    "        self.last_time = now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Existing Checkpoints &mdash; WARNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(checkpoints_dir):\n",
    "    os.makedirs(checkpoints_dir)\n",
    "\n",
    "for f in os.listdir(checkpoints_dir):\n",
    "    os.unlink(os.path.join(checkpoints_dir, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_vocab = Y_vectorization.get_vocabulary()\n",
    "Y_index_lookup = dict(zip(range(len(Y_vocab)), Y_vocab))\n",
    "max_decoded_sentence_length = max_length\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = X_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = Y_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = Y_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "\n",
    "train_data = make_dataset(X_train, Y_train, batch_size)\n",
    "test_data = make_dataset(X_test, Y_test, batch_size)\n",
    "\n",
    "demo_str = \"You should seek advice from a medical professional.\"\n",
    "\n",
    "filepath = os.path.join(checkpoints_dir, \"transformer-f2c-{epoch:02d}-{loss:.4f}.ckpt\")\n",
    "checkpoint = ModelCheckpoint(filepath, save_weights_only=True, monitor=\"loss\", verbose=0, save_best_only=True, mode=\"min\")\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_data),\n",
    "    callbacks=[Plotter(), checkpoint, PrintDemo(demo_str)]\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoints_dir)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"You should seek advice from a medical professional.\"\n",
    "\n",
    "start = time.time()\n",
    "pred_str = decode_sequence(test_str)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(test_str)\n",
    "print(\"->\")\n",
    "print(pred_str)\n",
    "print(f\"Took {elapsed:5f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe9152bf2f574327d6e225fe0caf6c004889fb08c66ba1e27720217847b14197"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
